
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>Science & Fun - Jonathan Graehl</title>
	<meta name="author" content="Jonathan Graehl">

	
	<meta name="description" content="Denials of misinformation from trusted experts are partially counterproductive; three days after reading a pamphlet correcting health myths, 40% of &hellip;">
	
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="Science & Fun - Jonathan Graehl" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
	
</head>

<body>
	<header id="header" class="inner"><h1><a href="/">Science & Fun - Jonathan Graehl</a></h1>
<nav id="main-nav"><ul class="main">
	<li><a href="/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul class="main">
	<li><a href="/">Blog</a></li>
	<li><a href="/blog/archives">Archives</a></li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="http://google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:graehl.org">
			</form>
		</div>
	</div>
</nav>
<nav id="sub-nav" class="alignright">
	<div class="social">
		
		
		
		<a class="twitter" href="http://twitter.com/graehl" title="Twitter">Twitter</a>
		
		
    
		
		
		
		
		
		<a class="rss" href="/atom.xml" title="RSS">RSS</a>
		
	</div>
	<form class="search" action="http://google.com/search" method="get">
		<input class="alignright" type="text" name="q" results="0">
		<input type="hidden" name="q" value="site:graehl.org">
	</form>
</nav>

</header>
	
		
	
	<div id="content" class="inner">


    <article class="post">
	<h2 class="title">
		
		<a href="/dignified-with-a-response/">
		
			Dignified With a Response</a>
	</h2>
	<div class="entry-content">
		     Denials of misinformation from trusted experts are partially counterproductive; three days after reading a pamphlet correcting health myths, 40% of people had within 3 days dropped the negation from the original &#8220;X is not true&#8221; in their memory, believing instead &#8220;X&#8221; and attributing the knowledge to the experts who&#8217;d said the opposite.  This is probably a worse state of affairs than before (unless the particular belief was both extremely harmful and widespread before exposure to the propaganda).  In any case, it seems like we should do better than to accidentally and absolutely convince 40% of people of a harmful untruth.<p></p>  If I wanted people to remember that X was wrong, I&#8217;d have an unattractive person directly advocate X, and viciously destroy him and his argument, preferably in public.  People seem to remember who&#8217;s embarrassed and who hates who.  I&#8217;ve seen this technique used in propaganda cartoons, and on Fox News with patsy liberal guests.<p></p>  From <a href="http://www.overcomingbias.com/2007/09/the-deniers-con.html">The Denier&#8217;s Dilemma:</a><br> <blockquote type="cite"><span style="border-collapse: separate; color: rgb(0, 0, 0); font-family: Times New Roman; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; text-indent: 0px;"><span style="color: rgb(53, 53, 55); font-family: Arial,Helvetica,sans-serif; font-size: 15px; line-height: 22px;">Ruth Mayo … found that for a substantial chunk of people, the &#8220;negation tag&#8221; of a denial falls off with time. … explaining why people who are accused of something but are later proved innocent find their reputations remain tarnished. … So is silence the best way to deal with myths? Unfortunately, the answer to that question also seems to be no.  Another recent study found that when accusations or assertions are met with silence, they are more likely to feel true</span></span></blockquote> <br> In that vein, Robin Hanson asks <a href="http://www.overcomingbias.com/2007/02/what_evidence_i.html">what conclusions we <i>should</i> draw</a> when a heavily promoted fringe belief (not accepted by official authorities) isn&#8217;t met with any substantial rebuttal.  Not only should we not believe fringe advocates just because they&#8217;re loud, fervent, and apparently unopposed, we should take the official silence as an implied rebuke.  <p></p>  I often wonder: when is it worth my effort to undertake my own investigation of the merits of the fringe argument, in depth sufficient that I could find the confidence to overcome the strong prior against them by nature of their fringe status?  In most cases, either the fringe claim is so incredible, or the advocates so flawed, that there&#8217;s no temptation.  In some cases, the payoff for correctly adopting a fringe belief seems low (if it&#8217;s true that excessive milk drinking is harming me, it probably isn&#8217;t by very much), even if the cost of gaining the information needed to decide it is modest.<p></p>  Prof. Hanson also suggests that when there is serious opposition to an idea, the fact that the opponents are diverse in their reasons and premises, is not evidence against them.  For example, people sometimes advocate racial (among other types of) profiling for the reason that it&#8217;s rational to avoid considering certain groups when you want to find a qualified person of <i>any</i> group as easily as possible, but Robin and others want to argue that it&#8217;s <a href="http://www.overcomingbias.com/2007/01/statistical_dis.html#comment-27862402">unfair and breeds crime</a>, for not enough benefit.  The argument for profiling is simpler and clearer, but since most of us don&#8217;t want to allow profiling, we should be consistent and not generally take &#8220;confusion in the opposition&#8221; as evidence.

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-09-22T11:43:59-07:00" pubdate data-updated="true">Sep 22<span>nd</span>, 2009</time></div>
	<div class="tags">

</div>
	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/a-foolish-consistency/">
		
			A Foolish Consistency</a>
	</h2>
	<div class="entry-content">
		     Growing up, we learn how to behave in a way that makes us a cog fit for society&#8217;s machine.  Parts of official and folk religion may become counterproductive if we keep them, while valuing rationality to the extent that we really begin to overcome hypocrisy and inconsistency.  Those parts would never have allowed our society to prosper if not for their protective companion conventional irrationalities.<p></p>  If you fix one bug in an incorrect computation while others remain, your answer may be more inaccurate than before.  So, if you&#8217;re both courageous and rational, please be careful before acting in a way that harms society; maybe the irrationality you just removed was part of your society&#8217;s protection against the logical consequences of another error you also need to discard.  For example, please consider abandoning your religion before committing acts of righteous terrorism.<p></p>  In this vein:<br> <a href="http://lesswrong.com/lw/18b/reason_as_memetic_immune_disorder/">LessWrong discussion</a><br> <a href="http://www.gnxp.com/blog/2007/04/nerds-are-nuts.php">Nerds are nuts</a>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-09-21T19:19:07-07:00" pubdate data-updated="true">Sep 21<span>st</span>, 2009</time></div>
	<div class="tags">

</div>
	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/crash-a-kind-of-movie-review/">
		
			Crash (a Kind of Movie Review)</a>
	</h2>
	<div class="entry-content">
		<p>crash: a pretty, fun, full-of-crap movie, with some powerfully acted moments (spoilers follow)</p>
<p>everywhere: tarantino-esque supposed to be funny-because-it&#8217;s-shocking racist repartee. the absolute low: &#8220;how did those two cultures (el salvadorian and puerto rican?) get together and decide to park their cars on the grass?&#8221;, said to his girlfriend in a fit of blue-balled pique.</p>
<p>coincidence #1: opening crash - cut to dazed detective getting out and finding his dead brother&#8217;s shoe on the side of the road</p>
<p>coincidence #2: molester cop randomly encounters molested woman next day and pulls her from her car just before it explodes (i was really pulling for him! it was a tasteful molestation, so he turned out ok)</p>
<p>coincidence #3: molester cop&#8217;s ex-partner also randomly encounters molested woman&#8217;s partner the same day and saves his life after he flips out and fights back against carjackers, then, continuing to run amok, attempts suicide-by-cop in a delayed reaction to his doormat-like acquiescence to her molestation-by-cop.</p>
<p>coincidence #4: one of the carjacker who failed in #3, later that night while hitchhiking ends up shot by the #3 lifesaving cop - while not emotionally significant, it&#8217;s still improbable that they would both have an independent relationship to the same car</p>
<p>obvious: evil HMO refuses to check molester&#8217;s dad for prostate cancer</p>
<p>obvious: imaginary bullet-proof cloaks and a blank ammunition</p>
<p>obvious: ludacris ironically railing against mumbling rappers</p>
<p>annoying: DA assistant&#8217;s sleazy/glib blackmail presentation</p>
<p>annoying: if you don&#8217;t want to rock the LAPD boat in order to leave your racist partner, you have to publicly claim uncontrollable flatulence</p>
<p>annoying: knowing the leaking gasoline would eventually reach the flame. (a person or a blanket would have easily been able to stop that flow)</p>
<p>retarded: molested woman&#8217;s partner brawling with two armed carjackers (we&#8217;re to understand that said carjackers, who earlier told us they would never steal from black people, won&#8217;t shoot)</p>
<p>retarded: detective&#8217;s brother / ludacris&#8217; carjacking partner getting himself shot and tragically having an idol of St. Somebody in his hand rather than a gun. i would have shot him too.</p>
<p>retarded: giving ludacris back his gun and telling him he embarrasses you</p>
<p>true and sad: producer telling above partner (also a TV director) to direct a black actor to &#8220;talk more black&#8221;</p>
<p>horrible person: hmo bureaucrat who admits she&#8217;s making prostate dad suffer because his molester son is racist</p>
<p>horrible person: persian father who was enough of a dick that i was happy his store was vandalized in possible retaliation</p>
<p>horrible person: detective&#8217;s mother. gross. her son is a saint for not raging against her.</p>
<p>horrible person: DA&#8217;s wife. disgusting in every way. her quasi-redemption did nothing for me - when she realizes she is angry all the time for no reason, when she realizes that her maid (who should hate her but is too saintly) is the only friend she has, i think &#8220;yes, you are horrible, and your husband treats you better than you deserve&#8221;</p>
<p>possibly horrible person: DA, because presumably he knows what his blackmailing subordinate did. &#8220;i need to pin a medal on a black person so i still get votes from people after i was carjacked by black people&#8221; was just stupid, not evil. it&#8217;s part of the morality of the film that as a politician, he must be tainted by evil, but i do enjoy his calm command. he seems reasonable to me.</p>
<p>horrible person: ludacris&#8217; carjacking partner.</p>
<p>horrible person: ludacris, until he&#8217;s conveniently redeemed by setting free the smuggled vietnamese locked in the back of the van he stole because he remembered it from the night before he hit-and-nearly-ran the night prior in the car he stole from the DA</p>
<p>horrible person: molester cop until he&#8217;s conveniently redeemed by heroically pulling the woman he molested from a car just prior to its explosion</p>
<p>nice person: locksmith (and his family), whether or not he vandalized the persian father who abused him and cheated him. horrible if in handing down invisible bulletproof cloak he scarred his daughter for life after he was shot (thanks, blanks) - which i was waiting for the entire movie.</p>
<p>nice person: persian daughter who bought the blanks</p>
<p>nice person: detective, provided he reneges on his deal to withhold exculpatory evidence now that his brother is dead</p>
<p>nice person: director who let his wife be molested.</p>
<p>nice person: not-racist cop, who rightfully shot his crazy hitchhiker (but he could have done MORE! we ALL could do MORE!)</p>
<p>overall: about the 300th best movie i&#8217;ve watched. pretty and well-acted. if you liked crash, magnolia does it better (equally believable and with less moralizing)</p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-09-07T03:11:00-07:00" pubdate data-updated="true">Sep 7<span>th</span>, 2009</time></div>
	<div class="tags">


	<a class='category' href='/blog/categories/movies/'>movies</a>, <a class='category' href='/blog/categories/reviews/'>reviews</a>


</div>
	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/using-primitive-scala/">
		
			Primitive Scala</a>
	</h2>
	<div class="entry-content">
		<p>A lower level (Scala) solution to <a href="http://dcsobral.blogspot.com/2009/09/puzzle.html">this puzzle</a>:</p>
<p><br> </p>
<div class="p_embed p_image_embed">
<img alt="Carpuzzle" src="/images/2009/09/05/using-primitive-scala/2296381-carpuzzle.png">
</div>

<p><br> There&#8217;s a path from the car to the exit on the right following the lines at corners, and emerging only at arrowheads. This is just a directed graph.  The two directions on a street segment are independent nodes.  I stole from Daniel Sobral the text representation of the graph, and implemented breadth first (shortest path) search just like he did.  The difference is that I explicitly represent the directed graph, and I do so in typical programming contest style.  He has a nice ASCII art printout; I just used simple debug prints to verify that I built the graph right.</p>
<p></p>  It bothers me that in JVM languages, wrapping a primitive in a type requires boxing (no matter how awesome just-in-time compilation is, there&#8217;s still memory overhead).  So I end up using a lot of bare primitives and arrays of primitives, probably to my detriment.  Clearly it&#8217;s not relevant for this problem (which even a human can solve), but it might eventually compel me to use C++ again (where things are miserable, but at least there&#8217;s no <a href="http://metamatix.org/%7Eocaml/price-of-abstraction.html">abstraction penalty</a>).  I believe .NET allows C-like structures of unboxed primitives, but I&#8217;m not satisfied that F# is as pleasant or efficient as Scala (even using my primitive-happy style).<p></p>  Obviously, most of the code is about translating the text graph description to the directed adjacency list.  It&#8217;s about half the lines of his version, but I won&#8217;t claim it&#8217;s easier to understand.
<p><span style="font-size: small;"><br></span> <tt><span style="font-size: small;">final case class Roadmap(rows: Int,cols: Int) {<br>   type Onto=Array[Int] // adjacency list<br>   type Roads=Array[Onto] // vertices (unidirectional road segments)<br>   val RC=rows*cols<br>   val ndir=4<br>   val goal=RC*ndir<br>   val DRC=RC*ndir<br>   val roads=new Roads(DRC) // one dimensional array allows for simpler adjacencies at the cost of uglier addressing<br>   /* separate road segment for each direction right left down up (0 1 2 3)<br>    so that (row,col) is the location of the upper/left corner of that segment (be consistent!)<br>    */<br>   def index(rldu: Int,row: Int, col: Int) = RC*rldu+row*cols+col<br>   def coord(i: Int) = { val rldu=i/RC;val r=i%RC;(rldu,r/cols,r%cols) }<br>   val R=0<br>   val L=1<br>   val D=2<br>   val U=3<br>   val NONE=4<br>   def c2dir(a: Char) = a match {<br>     case &#8216;R&#8217; =&gt; R<br>     case &#8216;L&#8217; =&gt; L<br>     case &#8216;D&#8217; =&gt; D<br>     case &#8216;U&#8217; =&gt; U<br>     case _ =&gt; NONE<br>   }<br>   def dir2c(d: Int) = &#8220;RLDUN&#8221;(d)<br>   def coordname(t: (Int,Int,Int))=t match {case (rldu,row,col) =&gt; &#8220;%c%d%d&#8221;.format(dir2c(rldu),row,col)}<br>   def i2s(i: Int)=coordname(coord(i))<br>   /* set the transitions that meet in the intersection on row r, col c.<br>      exits(dir) if there&#8217;s an arrowhead; undir is a list of pairs of linked dirs */<br>   def setCorner(r: Int, c: Int, exits: Array[Boolean], undirs: Array[(Int,Int)], goaldir: Int) {<br>     // remember, r,c gives the upper/left part of road<br>     val froms=Array(index(L,r,c),index(R,r,c-1),index(U,r,c),index(D,r-1,c))<br>     // to approach from the right, you head left.  froms and tos are identical except opposite directions<br>     val tos=  Array(index(R,r,c),index(L,r,c-1),index(D,r,c),index(U,r-1,c))<br>     val ways= Array.fill(ndir)(new collection.mutable.ArrayBuffer[Int](ndir))<br>     def checkdir(from: Int,to: Int) {<br>       if (goaldir==to) ways(from)+=goal<br>       else if (exits(to)) ways(from)+=tos(to)<br>     }<br>     for ((from,to)       checkdir(from,to)<br>       checkdir(to,from)<br>     }<br>     for ((f,w)       if (w.size&gt;0) roads(f)=w.toArray<br>       // since we didn&#8217;t pad the border, we&#8217;ve considered indices that are off the array.<br>       // user input must not ask us to move from somewhere off the array<br>       // a padded border would prevent this, and allow a single start and goal state<br>     }<br>   }<br>   def s2dirs(s: String) = (c2dir(s(0)),c2dir(s(1)))<br>   def readCorner(r: Int, c: Int, desc: String) {<br>     val a=desc.trim split &#8220;:&#8221;<br>     val exits=new

Array[Boolean](ndir)<br>     var lastdir=NONE<br>     var goaldir=lastdir<br>     for (

c       if (c==&#8217;!&#8217;) goaldir=lastdir<br>       else {<br>         val d=c2dir(c)<br>         if (d!=NONE) {<br>           exits(d)=true<br>           lastdir=d<br>         }<br>       }<br>     }<br>     setCorner(r,c,exits,a(1).trim split &#8221; &#8221; map s2dirs toArray,goaldir)<br>   }<br>   def read(s: String) = {<br>     var r=0<br>     for ((line,row)=0) zipWithIndex) {<br>       for ((s,col)         readCorner(row,col,s)<br>       }<br>     }<br>   }<br>   def path2goal(starts: Int*) = {<br>     type Path=List[Int]<br>     val q=new collection.mutable.Queue[Path]<br>     val seen=new Array[Boolean](DRC)<br>     starts foreach (seen(_)=true)<br>     val s=starts map (x=&gt;List(x))<br>     q.enqueue(s: _*)<br>     var p=q.head<br>     while (p.head != goal) {<br>       val </span><span style="font-size: small;">

h=p.head<br>       seen(h)=true<br>       val n=roads(h) map (_::p)<br>       q enqueue (n: _*)<br>       p=q dequeue<br>     }<br>     p<br>   }<br>   def prettypath(p: List[Int]) = p reverseMap i2s<br> }<p></p> object car {<br> /* from </span> <a href="http://dcsobral.blogspot.com/2009/09/puzzle.html" class="moz-txt-link-freetext"><span style="font-size: small;">http://dcsobral.blogspot.com/2009/09/puzzle.html</span></a><span style="font-size: small;"> */<br>   val graphString = &#8220;&#8221;&#8220;|<br>                        |DR: DR, RLD: RD LD, L: DL LR, LR: DR LR, DL: DL<br>                        |UR: LU RU DU LR, LRD: LR UD LU RU LD RD, UDLR: UD LR UR LD, UDLR: UD LR RD, UL: UD UL<br>                        |UDR: UD RU RD, UDLR: LR LD DR RU, UD: UD UL DL, UDR: UD UR, UD: UD LD<br>                        |UDR: UD RU RD, UDLR: UR UL LR RD, UR: UD LR LU RU DR, ULR: LR UR UL DR DL, UDLR!: UD UL DR<br>                        |UR: UR, ULR: UL UR LR, ULR: UL UR RL, ULR: UL UR RL, UL: UL<br>                        |&#8221;&#8220;&#8221;.stripMargin<br>   def main(args: Array[String]) {<br>     val r=Roadmap(5,5)<br>     r.read(graphString)<br>     println(r.prettypath(r.path2goal(r.index(r.R,1,0),r.index(r.U,0,0))))<br>   }<br> }<br></span> </tt><br> The format is explained on Daniel&#8217;s blog, but I found it odd enough that I&#8217;ll mention that it&#8217;s a matrix of intersections with EXITS: UNDIRECTED_ADJACENCIES.  EXITS is the list of directions that have a departing arrowhead.  The adjacencies are undirected to save typing (UR means both UR and RU).  I added a ! following the arrowhead if it leads to the goal, since I didn&#8217;t want to hard code the exit location.</p>
<p></p>  Because I didn&#8217;t create any node for the car&#8217;s starting location, I just started the search from both the initial turns available.
<p>(SPOILER: R10, R11, D12, D22, R32, U23, U13, U03, R03, D04, L13, D13, R23, D24, D34, L43, L42, L41, L40, U30, U20, R20, D21, L30, D30, R40, R41, R42, R43, U34, where 32 means the road segment with its upper left at row 3 and column 2)</p>
<p></p>
<div class="p_embed p_image_embed">
<img alt="Carpuzzle" src="/images/2009/09/05/using-primitive-scala/2296381-carpuzzle.png">
</div>

<p></p>
<p><a href="https://gist.github.com/181632">https://gist.github.com/181632</a></p>

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-09-05T20:36:00-07:00" pubdate data-updated="true">Sep 5<span>th</span>, 2009</time></div>
	<div class="tags">

</div>
	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/tree-pattern-matching/">
		
			Tree Pattern Matching</a>
	</h2>
	<div class="entry-content">
		<p><a href="http://aclweb.org/anthology-new/D/D09/D09-1108.pdf">Fast Translation Rule Matching for Syntax-based Statistical Machine Translation</a><br> in EMNLP09 (Zhang et. al) gives a practical method for top-down enumerating tree pattern matches against the root of a forest (compact regular set of trees).  This problem arises in MT when you first context-free-parse your source material, and then transform its syntax tree into another language - since parsers aren&#8217;t perfect, you translate all the likely parses rather than just the most likely, and pick the most likely and fluent output.  Apparently the baseline pattern matching methods used are <em>really</em> terrible:</p>
<ol>
<li>EITHER: Up to the largest rule size/shape iterate over the (exponential in that size) many forest-topping label sequences, checking each against a rule label sequence hash. </li>
<li>OR: Iterate over all the rules, checking each one independently against the forest.  </li>
</ol>
<p>They give an improvement to the latter approach: if you&#8217;ve already matched the first 3 levels of a 4-height rule before, don&#8217;t repeat the work.  (The <a href="http://aclweb.org/anthology-new/D/D09/D09-1108.pdf">diagrams</a> are pretty good; refer to them if you want to make sense of what follows). This is 20 times faster, and makes their overall MT system twice as fast.  If you&#8217;re actually using one of the above horrible baseline approaches, you would do well to emulate this paper.  I suspect that people are in practice using a hybrid of the two: exhaustively unpack the forest for a set of (small) top-of-tree-shapes e.g. x(x(x,x),x), retrieving potential rule sets by labels-hash, and then iterating over the resulting subset.  Unfortunately, they only compare their performance against the two (stupid) extremes.  I&#8217;ll also note that it always makes sense to (reversibly) binarize both the forest and the tree patterns in the same way, if you haven&#8217;t already, e.g. A(B,C,D) binarized would be: A(B,C_D(C,D)) where C_D is a virtual nonterminal that only appears in the context C_D(C(&#8230;),D(&#8230;)).</p>
<p></p>  The avoidance of (some) repeated work is accomplished by 1) organizing tree patterns (rule left hand sides) to reflect these shared upper levels and 2) performing exhaustive top-down breadth-first expansion of pairs of (pattern state, forest states - one for each leaf in pattern state), where the forest states tuple may grow exponentially with depth.  Since we&#8217;re interested in the subforests aligned to the leaves of our tree pattern, we would take the forest states for pattern states corresponding to complete patterns, and perform some computation (MT in this case) on the subforests + pattern - we don&#8217;t just want the set of matching tree patterns.<p></p>  This paper could have been clearer and shorter. The pseudocode has quirks.  It also seems to cite without reading: <a href="http://www.isi.edu/natural-language/projects/rewrite/decoding-cl.ps">Decoding Complexity in Word-Replacement Translation Models</a> (Knight 1999) does <em>not</em> show MT in general is NP-hard, only that IBM Model 1 (one of the simplest word to word translation models, with very free word reordering) is. MT based on parsing, without global features, is actually polynomial (albeit high degree if you have e.g. target 5gram probabilities).<p></p>  Even though the forests arising from a parser will have the same root label for all trees in a state (e.g. NP covering words 1-2 has only NPs), I prefer the <a href="http://en.wikipedia.org/wiki/Regular_tree_grammar">regular tree grammar</a> formalism for a set of trees, where a grammar state can have production with different tree roots.  This paper handles the case where each state has a single unique tree root, since that&#8217;s what their parser gives them.  A general RTG production of rank k would need to be unpacked into N^k productions to achieve this, where N is the size of the tree label alphabet.  It&#8217;s better to modify your algorithm to use (root-label,forest-state) tuples instead of just (forest-state) whenever you want to look at only same-root trees.  I&#8217;m using &#8220;state&#8221; instead of the usual &#8220;nonterminal&#8221; to avoid confusion with the labels of the parse tree (in parsing, NP is a called a &#8220;nonterminal&#8221; of the tree NP(NN(dog))) since it&#8217;s not a &#8220;terminal&#8221;, or leaf).<p></p>  Everything in the paper is called &#8220;hyper-X&#8221;.  There&#8217;s even a section called &#8220;hyper-node, hyper-path and hyper-tree&#8221;.  I appreciate the enthusiasm, but these are not great names, especially since they&#8217;re (misleadingly) suggestive of vertex/node, hyperpath, and hypertree in hypergraphs.  The forest is also given as a set of &#8220;hyper-edges&#8221; (without definition, but obviously they mean a directed B-hyperedges with ordered tails).<p></p>  Obviously if the parse forest has probabilities attached to productions, you will have accumulated those in the process of finding a particular match.<p></p>  The authors could have cited, for the related problem of matching a set of tree patterns against a single tree, <a href="http://portal.acm.org/citation.cfm?id=322290.322295">Pattern Matching in Trees</a> (Hoffman and O&#8217;Donnell 1982).  That work deals with ranked tree labels (doesn&#8217;t provide a way to say &#8220;subtree rooted in a NP of any arity&#8221;; you&#8217;d have to have NP(x) NP(x,x) NP(x,x,x) &#8230;), but that&#8217;s always a trivial change.  As far as I can tell, it&#8217;s impossible to use the top-down matching scheme in that paper efficiently on forests.<p></p>  Hoffman and O&#8217;Donnell provide a helpful framework: the (immediate) subsumption graph of tree patterns.  This is a directed acyclic graph with edges from a to b if a&gt;b (a&gt;b (&#8220;subsumes&#8221;) iff \forall f a(f) =&gt; b(f)), where I&#8217;ve used a and b as predicates over trees or tree-sets f.  Immediate just means that only the necessary edges are kept (subsumption is transitive).  In the immediate subsumption graph pictured below, v means a variable, i.e. label can be anything:<br> <div class="p_embed p_image_embed">
<img alt="Subsumption" src="/images/2009/08/06/tree-pattern-matching/1216125-subsumption.png">
</div>
<br> Top-down matching procedures that report each assignment of subforests to tree pattern variables exactly once, will need to turn the subsumption graph into a tree.  Most likely you&#8217;ll want to do this in advance.  I&#8217;ve done this in a depth-first leftmost-expansion fashion by turning each tree pattern into a string, and combining the results into a trie with branching choice of &#8220;where to expand next&#8221;, implicitly giving a tree subgraph of the immediate subsumption graph (unpublished work).  Since I allow tree labels to have variable arity, I separate the choice of a label and its arity (the latter may never be specified).  My algorithm for matching this subsumption subgraph against a forest is the same as Zhang et. al, except that they&#8217;re breadth first, and they (unnecessarily) expand the whole level at once.  That is, their subsumption subgraph is not immediate.  They lose some sharing as a result, although it would be easy to fix this.  You can devise pattern sets that make a particular subsumption graph-&gt;tree mapping perform badly, and I don&#8217;t have any intuition as to whether theirs or mine will perform better on particular sets (e.g. MT rules containing most naturally occurring tree fragments up to a fixed size or depth).<p></p>  The lost sharing from top-down matching any particular subsumption tree can be avoided entirely with bottom-up matching.  Hoffman+O&#8217;Donnell give a method for building a bottom-up deterministic tree recognizer, which is certainly optimal with respect to sharing and probably time if you can afford to precompute and store the (possibly exponential) monster.  Bottom up tree recognizers can match against forests beautifully, since <a href="http://en.wikipedia.org/wiki/Regular_tree_grammar">regular tree grammars</a> are closed under intersection.  Unlike top-down matching, the result of bottom-up matching would just be a set of rule (fragments) for each forest node.  To get the subforests, you&#8217;d have to traverse top-down (this should be pretty fast, since you&#8217;re constrained by a specific tree pattern).  In a future post, I&#8217;ll describe a bottom-up patterns against forest (or tree) matching that doesn&#8217;t explicitly determinize beforehand.  I&#8217;ll also note that the type of sharing you get in bottom up matching is avoiding work in repeatedly matching subtrees that are contained in different rules.  On the other hand, subsumption avoids repeated work in matching shared <em>tops</em> of trees.  That is, a pattern that subsumes another is always larger (turning some leaves into full subtrees).<p></p>  Also, although I haven&#8217;t yet read it, <a href="http://www.cis.nctu.edu.tw/%7Ewuuyang/papers/A121.ps">A Simple Tree Pattern-Matching Algorithm</a> claims to improve Hoffman+O&#8217;Donnell.  It&#8217;s unlikely that this would be useful for forest matching.

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-08-06T12:29:00-07:00" pubdate data-updated="true">Aug 6<span>th</span>, 2009</time></div>
	<div class="tags">

</div>
	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/emnlp-mt-system-combination-papers/">
		
			EMNLP MT System Combination Papers</a>
	</h2>
	<div class="entry-content">
		I&#8217;ve skimmed a the system combination papers mentioned at <a href="http://nlpers.blogspot.com/2009/08/acs-machine-translation-papers-at-emnlp.html">ACS:
Machine Translation Papers at EMNLP.</a><br>
<hr size="2" width="100%">System combination can give large
improvements in MT quality, but in practice you have to ask people to
translate material for you on their system.<br>
<a href="http://aclweb.org/anthology-new/D/D09/D09-1114.pdf">Duan et al.</a>
(Feature Subspace Method for SMT System Combination) take a single
system and create a dozen variants of it (each leaving out a single
feature, or using a lower-order language model), and gain about 1 BLEU
by doing sentence-level rescoring using ngram-agreement and internal
model features (weights trained on a dev set).  This is more than the
modest 0.25 BLEU I&#8217;ve obtained by doing the same thing for a single
system&#8217;s nbests; they didn&#8217;t report their single-system reranking gain
but it&#8217;s probably similar.<p></p>

When combining two actual systems (Hiero-style and phrase-based), they
have to leave out the internal features (which are difficult or
impossible to evaluate on an unrelated system output), but still get an
additive ~1 BLEU when using 2*12 than 2*1 systems.  They also found
that 20-50 nbests were best (this agrees with my experience in sentence
reranking, but obviously that&#8217;s dependent on the search errors,
duplicate derivations, and other properties of the actual system and
search procedure; sometimes I&#8217;ve found a small benefit from up to
1000-bests).<p></p>

This is an excellent result and easy (if tedious) to apply to your own
system(s).  I don&#8217;t find their theoretical motivation particularly
compelling.  It seems to me that all the benefits are explained in
terms of Bayesian averaging over multiple feature-weight vectors.<br>
<hr size="2" width="100%">
<a href="http://aclweb.org/anthology-new/D/D09/D09-1115.pdf">Feng et al.</a>
(Lattice-based System Combination for SMT) take the nice word-level
(&#8220;sausage graph&#8221;) confusion network IHMM system combination method of
Xiadong He, and take the obvious step of generating lattices.  They get
another 0.5-1 BLEU over his result.  They build the lattice from word
to word alignments against a backbone translation, as in the CN case,
so it&#8217;s impressive that they get a meaningful lattice.  My own thought
would be to have the MT systems output alignment information directly,
but their way makes integration easier.  <p></p>

It&#8217;s also possible to get much of the benefit from a lattice&#8217;s phrases
by using system preferences for ngrams as a feature on top of the
unigram CN; <a href="http://www.aclweb.org/anthology/N/N09/N09-2052.pdf">Zhao &amp; He</a>
get almost identical improvement by doing so (they also add the usual
ngram-agreement reranking feature, where you treat your weighted nbest
as an English LM, into their CN decoder, which is smart).  If you have
an existing CN system, it&#8217;s probably easier to do this than switch to
lattices (there&#8217;s no reason not to try to combine the methods, but they
do very similar things already).<p></p>

<a href="http://aclweb.org/anthology-new/D/D09/D09-1125.pdf">He &amp;
Toutanova</a> (Joint Optimization for MT Sytem Combination) also amend
He&#8217;s original approach, and get a larger improvement (1.5 BLEU).  The
original CN IHMM approach was a pipeline of several greedy/hard
decisions; this work fixes that by jointly searching possible
reorderings/alignments/selections of phrases from the nbest
translations.  There&#8217;s probably not any way to &#8220;add lattices&#8221; on top of
this; there&#8217;s no explicit backbone, and they already use bigram system
voting.  I&#8217;d try new features before considering lattices (e.g. nbest
ngram LM, 3gram voting).  They show that the integrated alignment
search is important; they lose 0.3 BLEU if they restrict the search to
Viterbi union alignments.

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-08-03T19:04:57-07:00" pubdate data-updated="true">Aug 3<span>rd</span>, 2009</time></div>
	<div class="tags">

</div>
	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/a-wrong-alternative-01-knapsack-solver/">
		
			A Wrong &#8220;Alternative&#8221; 0/1 Knapsack Solver</a>
	</h2>
	<div class="entry-content">
		Be suspicious of algorithms given without proof of correctness, even if
they do appear on the first page in Google.<p></p>

<a href="http://penguin.ewu.edu/%7Etrolfe/Knapsack01/Knapsack01.html">An
Alternative Dynamic Programming Solution for the 0/1 Knapsack</a> is
&#8220;alternative&#8221; as in homeopathy.  It&#8217;s appealingly somewhat simpler than
the <a href="http://en.wikipedia.org/wiki/Knapsack_problem#0-1_knapsack_problem">standard
solution</a>.<p></p>

From their <a href="http://penguin.ewu.edu/%7Etrolfe/Knapsack01/Knap01Grid.java">Java
implementation</a>:<br>
<blockquote type="cite">
<big><span style="border-collapse: separate; color: rgb(0, 0, 0); font-family: Times New Roman; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; text-indent: 0px;">
  </span></big><div class="CodeRay">
  <div class="code"><pre>// Initial guess:  the knapsack for wt-1.
   bestVal[wt] = bestVal[wt-1];</pre></div>
</div>

  </blockquote>
That already causes some sub-optimal solutions.  I <a href="http://paste.pocoo.org/show/128686/">fixed</a> that, but that
only reduced the frequency of wrong solutions.  For the input:<p></p>

<blockquote type="cite">204
  <br>
9
  <br>
2 2
  <br>
81 81
  <br>
82 82
  <br>
182 182
  <br>
142 142
  <br>
11 11
  <br>
31 31
  <br>
61 61
  <br>
101 101
  <p></p>
  
</blockquote>
The &#8220;alternative solution&#8221; given is:<br>
<blockquote type="cite">(142, 142)
  <br>
(61, 61)
  <br>
Total weight:  203
  <br>
Total value:   203
  <br>
</blockquote>
But this is better:<br>
<blockquote type="cite">(31+61+101 = 204)
</blockquote>
The problem: the &#8220;alternative&#8221; solution has already used 31 in summing
to (204-31), 61 in summing to (204-61), and 101 in summing to
(204-101).  If the input is ordered differently, this may not happen -
all 3 of those coincidences need to occur for the algorithm to fail.<p></p>

The algorithm wrongly commits to just one way of reaching a given sum,
unlike the standard (correct) solution.

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-07-30T16:17:45-07:00" pubdate data-updated="true">Jul 30<span>th</span>, 2009</time></div>
	<div class="tags">

</div>
	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/reporting-peak-memory-used-on-program-exit-li/">
		
			Reporting Peak Memory Used on Program Exit (Linux)</a>
	</h2>
	<div class="entry-content">
		Python: <p></p>

    os.system(&#8216;cat /proc/%d/status | grep Vm&#8217; % os.getpid())<p></p>

Perl:<p></p>

    system &#8220;cat /proc/$$/status&#8221;<p></p>

VmPeak is the peak virtual memory size, and VmHWM (high water mark) is
the peak physical memory (RSS).  This beats polling using top - you can
report once at the very end.

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-07-29T18:01:41-07:00" pubdate data-updated="true">Jul 29<span>th</span>, 2009</time></div>
	<div class="tags">

</div>
	
</div></article>


    <article class="post">
	<h2 class="title">
		
		<a href="/scala-extension-methods-proposal/">
		
			Scala Extension Methods Proposal</a>
	</h2>
	<div class="entry-content">
		<a href="http://jorgeortiz85.github.com/ImplicitClassSIP.xhtml">http://jorgeortiz85.github.com/ImplicitClassSIP.xhtml</a> should be adopted, no matter whether Sun&#8217;s JVM optimizes temporary objects away, if only for the simpler syntax. <p></p> Just because you can do amazing things in libraries like Boost using C++ templates and preprocessor, doesn&#8217;t mean the language wouldn&#8217;t be better if it could express basic idioms more directly, even at some burden to the language implementer. Pimp My Library is like Boost.Lambda (C++0x will provide a real lambda, albeit without safely handling closure of captured stack variables).

		
		
	</div>


<div class="meta">
	<div class="date">








  


<time datetime="2009-07-24T16:58:45-07:00" pubdate data-updated="true">Jul 24<span>th</span>, 2009</time></div>
	<div class="tags">

</div>
	
</div></article>

<nav id="pagenavi">
    
        <a href="/blog/page/19/" class="prev">Prev</a>
    
    
    <div class="center"><a href="/blog/archives">Blog Archives</a></div>
</nav></div>
	<footer id="footer" class="inner">Copyright &copy; 2013

    Jonathan Graehl

</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->




	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-22982312-2']);
		_gaq.push(['_trackPageview']);

		(function() {
			var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
		})();
	</script>



</body>
</html>